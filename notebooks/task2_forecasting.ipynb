{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f4659-d2d0-4105-9f99-15019885bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "# ARIMA\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load TSLA data (cleaned from Task 1)\n",
    "data_folder = os.path.join(\"..\", \"data\")\n",
    "plots_folder = os.path.join(\"..\", \"plots\")\n",
    "os.makedirs(plots_folder, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_folder, \"TSLA.csv\"), parse_dates=[0], index_col=0)\n",
    "df[\"Daily_Return\"] = df[\"Close\"].pct_change()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "train_df = df.loc[\"2015-07-01\":\"2023-12-31\"][\"Close\"]\n",
    "test_df = df.loc[\"2024-01-01\":\"2025-07-31\"][\"Close\"]\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "# --- ARIMA ---\n",
    "print(\"\\n--- Training ARIMA ---\")\n",
    "model_arima = pm.auto_arima(train_df, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "print(\"Best ARIMA order:\", model_arima.order)\n",
    "\n",
    "arima_fit = ARIMA(train_df, order=model_arima.order).fit()\n",
    "arima_pred = arima_fit.forecast(steps=len(test_df))\n",
    "\n",
    "arima_mae = mean_absolute_error(test_df, arima_pred)\n",
    "arima_rmse = math.sqrt(mean_squared_error(test_df, arima_pred))\n",
    "arima_mape = np.mean(np.abs((test_df - arima_pred) / test_df)) * 100\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_df, label=\"Train\")\n",
    "plt.plot(test_df, label=\"Test\")\n",
    "plt.plot(test_df.index, arima_pred, label=\"ARIMA Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"ARIMA Forecast vs Actual (TSLA)\")\n",
    "plt.savefig(os.path.join(plots_folder, \"task2_arima_forecast.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(f\"ARIMA MAE: {arima_mae:.4f}, RMSE: {arima_rmse:.4f}, MAPE: {arima_mape:.2f}%\")\n",
    "\n",
    "# --- LSTM ---\n",
    "print(\"\\n--- Training LSTM ---\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(train_df.values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 60\n",
    "X_train, y_train = create_sequences(scaled_train, seq_length)\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# Test data for LSTM\n",
    "full_scaled = scaler.transform(df[\"Close\"].values.reshape(-1, 1))\n",
    "X_test, y_test = create_sequences(full_scaled[len(train_df)-seq_length:], seq_length)\n",
    "y_test_actual = df[\"Close\"].values[len(train_df):]\n",
    "\n",
    "lstm_pred_scaled = model_lstm.predict(X_test)\n",
    "lstm_pred = scaler.inverse_transform(lstm_pred_scaled)\n",
    "\n",
    "lstm_mae = mean_absolute_error(y_test_actual, lstm_pred)\n",
    "lstm_rmse = math.sqrt(mean_squared_error(y_test_actual, lstm_pred))\n",
    "lstm_mape = np.mean(np.abs((y_test_actual - lstm_pred.flatten()) / y_test_actual)) * 100\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_df.index, train_df, label=\"Train\")\n",
    "plt.plot(test_df.index, test_df, label=\"Test\")\n",
    "plt.plot(test_df.index[seq_length:], lstm_pred, label=\"LSTM Forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"LSTM Forecast vs Actual (TSLA)\")\n",
    "plt.savefig(os.path.join(plots_folder, \"task2_lstm_forecast.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(f\"LSTM MAE: {lstm_mae:.4f}, RMSE: {lstm_rmse:.4f}, MAPE: {lstm_mape:.2f}%\")\n",
    "\n",
    "# --- Model Comparison ---\n",
    "if arima_rmse < lstm_rmse:\n",
    "    best_model = \"ARIMA\"\n",
    "else:\n",
    "    best_model = \"LSTM\"\n",
    "\n",
    "print(f\"\\nBest model based on RMSE: {best_model}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
